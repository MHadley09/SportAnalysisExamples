**Human** - This is my personal poll, this is made without looking at any polls (AP, Coaches, computer).  I also do not reference my previous polls when making this one.  I also have a firm rule that teams much have a 0.667 record to appear in the poll, this is because early it allows smaller teams to get a spotlight and my poll method is very non-sticky so there is no reason to put teams in until they have proven it over a number of games.  This means this week 3 loss teams with 6 wins are back on the table.  Eventually this poll may be removed as the season goes on.  This poll is only counted for a single vote.

**MLE** - This is my "Most Likely ELO" model.  Do not let the name fool you, it is not an ELO model.  ELO is simply the function used to determine the stabilitization point.  This model takes the games played thus far and treats them as the result of one function.  The function takes 2 teams evaluations as inputs to get their games result.  It finds the best fit evaluation for which our test function has the closest results to the actual game results.  Games are scored by percentage chance to win a rematch based on each teams score and lots of regression testing.  The biggest issue with this model is until week 7 or 8 there are multiple solutions to our function so results can get wonky if we hit a valley.

**Page** - This model is a much more complex derivative of the Google Page Rank reapplication I have talked about at lenght.  In the models I have traditionally discussed here, losses are forwarded linked and we solve our matrix and go on our way.  In this new model, it runs 2 Page Rank variants, in one losses are forward linked in the other wins are forward linked.  We take the scores from the loss forward linked run and subtract half the win forward linked scores.  This gives us a much smoother range and prevents one big win from pushing a team to the top despite a large number of losses.  This model favors teams that have played more games as they have more chances to form links into themselves.  This leads to teams like Ohio State who have their bye early being slightly deflated.  This will correct itself as the season goes on.

**QELO** - This is a varation of an ELO model.  Unlike MLE, this is actually an ELO based model.  It is lightly seeded with G5 starting 200 points lower than P5 and FCS starting at half.  This model looks at games down to DII.  To prevent early seeding or order of games from having to great an impact it does 2 passes.  The first pass is down with the seeding and runs through the season forward, the second pass runs through the season backwards and continues from the forward pass results.  This model, as an ELO model, can suffer from some recency bias or beating a team at the right time being a huge boon though this helps prevent it.  This model also suffers slightly from byes being heavily punished early.  The Q stands for quality.  This measure the quality of the win rather than using a 1 or 0 to revelaute ELO after each game.  This model uses score, luck margin, and overtime to determine, rematch win rate.  The winning team always is guarrenteed to be given a 52% rematch win rate, but is capped at 60% if overtime occurs.  Luck is determined by unforced turnovers, forced turnovers are not factored into luck. (This is super subjective and done by hand so it doesn't get a huge say).

 
**NSoR** - This is my naive strength of record model.  In this context naive doesn't mean dumb or bad, it means that it doesn't use any form of regression or machine learning to refine its results.  This is a simple run through a create a strength of record based on basic ratings of the opponent's offense and defense.  This model does not use a true record despite its name.  I find the Pythagorean record much more accurate representation of a team thus any place in this model a record is used the Pythagorean record is used instead.

**Skill** -This is my true skill model.  It attempts to determine an offensive and defensive rating for each team using a regression analysis model on their game data.  These scores represent the amount of points a team would sccore and allow against the average FBS team.  These scores are then shifted to a linear scale with the number 1 team have a score of 1 and the last place team to have a score of 0.0.  These two scores are then compared with a performance skill which is based on the Pythagorean record and pythagorean strength of schedule model.  Once we have a full ranking the performance skill, we combine these measures to generate a ranking.

**Wins Over** - This is my latest creation.  I had toyed with the idea for a while based on models I had seen around.  It is also based on the concept of expected performance.  The model runs an initial estimated ranking.  These rankings are used to generate an expected Pythagorean wins an above average team (a team on the border of the top 25) would have against this schedule.  It compares this to the Pythagorean wins a team actually had to see how far over above expected wins they are performing.

**Margin** - This model is another log likelihood based model.  This model takes scores of very game and tries to find a score for each team that minimizes the rating of team A - the rating of team B to be as close to the actual margin of victory or loss for every team across all games.  It places a soft cap on margin of victory of 28 anything above that and points are weighted less and less.  The functional cap is around 42 points past this and the impact of additional points is completely negligible.

**Power Rank** -  This model uses by predictive model's generated fingerprints to determine adjusted performance over opponent's average as well as a strength of schedule adjusted record to determine a ranking.

**SimuRank** -  This model runs a full simulated season wherein each team plays 250 neutral site games against every other team using the same simulator I have used the past 3 years for my prediction and analysis posts.  The model ranks team by the record of the simulated season.~~ NOT PRESENT THIS WEEK
**Future Skill** - This model, along with the Future Rank, were models I have been toying with for a long time.  A key difference between human and computer polls is many human polls attempt to rank teams where they think they will finish the season ranked based on how they expect them to perform in remaining games as well how they have performed to this point.  This model projects performances for the remaining games and based on this additional data attempts to calculate my of S&P/+. 


~~**Future Skill** - This model, along with the Future Rank, were models I have been toying with for a long time.  A key difference between human and computer polls is many human polls attempt to rank teams where they think they will finish the season ranked based on how they expect them to perform in remaining games as well how they have performed to this point.  This model projects performances for the remaining games and based on this additional data attempts to calculate my of S&P/+.~~ No longer relevant as not enough future games in regular season. .

~~**Future Rank** - This model, along with the Future Skill, were models I have been toying with for a long time.  A key difference between human and computer polls is many human polls attempt to rank teams where they think they will finish the season ranked based on how they expect them to perform in remaining games as well how they have performed to this point.  This model converts every game so far into a likelihood of winning a rematch based on score of the first game.  Then using my simulation model it projects the win likelihood percentage of each remaining game.  The model attempts to project where the teams will most likely finished ranked in human polls based on these results.~~ No longer relevant as not enough future games in regular season.
